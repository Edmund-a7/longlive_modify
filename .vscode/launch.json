{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "torchrun 调试 inference.py",
            "type": "debugpy",
            "request": "launch",
            "module": "torch.distributed.run",
            "args": [
                "--nproc_per_node=1",
                "--master_port=29500",
                "${workspaceFolder}/inference.py",
                "--config_path",
                "${workspaceFolder}/configs/longlive_inference.yaml"
            ],
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "2"
            }
        }
    ]
}